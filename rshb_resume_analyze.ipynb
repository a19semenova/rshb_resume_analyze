{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a8f335-1ef0-4c7a-8160-fcc9ad1f8594",
   "metadata": {},
   "source": [
    "Код токинизации фраз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c62d35-547b-44ac-bb69-fbfae4c1dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction import text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "from IPython.display import Markdown, display, HTML\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "freq_limit = 86400 / 2\n",
    "time_start = int(datetime.datetime.strptime('01-01-2020', '%d-%m-%Y').strftime(\"%s\"))\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
    "data = json.load(open('vacancy.json'))\n",
    "\n",
    "locals_dict = dict.fromkeys(['user127586289','user68513872','user1471788','user125042168','user92008355','user125418312','user100782243','user82639411','user153030146',\n",
    "'user291176400','user73173481','user551102','user188075071','user53629404','user1032579','user194201144','user162658742','user158187166',\n",
    "'user116682853','user82230092','user113976012','user3797167','user94299908','user230762864','user119852384','user202423560','user407081565',\n",
    "'user115002256','user543084133','user163171491'], True)\n",
    "\n",
    "stop_words = stopwords.words(\"russian\")\n",
    "stop_words.extend([\n",
    "    'умение', 'навык', 'уверенное', 'владение', 'знание', 'опыт', 'умение', 'работать', 'навык', 'работы', \n",
    "    'понимание', 'глубокое', 'владение', 'осведомленность', 'уровень', 'знаний', 'практический', 'опыт',\n",
    "    'профессиональное', 'владение', 'применять', 'основ', 'анализировать', 'уверенность'\n",
    "])\n",
    "\n",
    "stop_words_dict = dict.fromkeys(stop_words, True)\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(\"[.,\\-!?:()\\[\\]]+\", \" \", text)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    for w in text.split():\n",
    "        w = morph.parse(w.lower())[0].normal_form\n",
    "        \n",
    "        if w in stop_words_dict:\n",
    "            continue\n",
    "        \n",
    "        if result: result += ' '\n",
    "        result += w\n",
    "    \n",
    "    return result\n",
    "\n",
    "member_time = {}\n",
    "messages = []\n",
    "\n",
    "for m in data['messages']:\n",
    "    t = int(m['date_unixtime'])\n",
    "    \n",
    "    if t < time_start:\n",
    "        continue\n",
    "\n",
    "    if 'from_id' in m and t:\n",
    "        if m['from_id'] in locals_dict:\n",
    "            continue\n",
    "            \n",
    "        if m['from_id'] not in member_time or t - member_time[m['from_id']] > freq_limit:\n",
    "            msg = ''\n",
    "            for item in m['text_entities']:\n",
    "                if item['type'] == 'plain':\n",
    "                    msg += item['text']\n",
    "            \n",
    "            if len(msg) > 40:\n",
    "                msg = re.sub(\"\\n{1,}\", \" \", msg)\n",
    "                msg = msg.strip(\"\\n \")\n",
    "                msg = re.sub(\" {1,}\", \" \", msg)\n",
    "                messages.append(msg)\n",
    "                \n",
    "        member_time[m['from_id']] = t\n",
    "        \n",
    "print(len(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32068e32-13c2-4476-8705-83cdccb06a78",
   "metadata": {},
   "source": [
    "Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d4b125-2839-4298-8c4d-a7a90ef9af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "processed_messages = []\n",
    "\n",
    "for m in messages:\n",
    "    processed_messages.append(preprocess(m))\n",
    "    \n",
    "x = vectorizer.fit_transform(processed_messages)\n",
    "\n",
    "true_k = 30\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=2000, n_init=50, tol=1e-1)\n",
    "model.fit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5eb8ce-3b98-4da6-9d95-b9e637da6980",
   "metadata": {},
   "source": [
    "Визуализируем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31aa79-34ff-4927-85ea-28eabd75064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "clustered = {}\n",
    "\n",
    "for m in messages:\n",
    "    y = vectorizer.transform([preprocess(m)])\n",
    "    p = model.predict(y)[0]\n",
    "    \n",
    "    if p not in clustered:\n",
    "        clustered[p] = [m]\n",
    "    else:\n",
    "        clustered[p].append(m)\n",
    "        \n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(0,true_k):\n",
    "    printmd (\"**Кластер {n} ({l})**\".format(n=i, l=len(clustered[i])))\n",
    "    \n",
    "    w = ''\n",
    "    for c in order_centroids[i, :10]:\n",
    "            w += '<span style=\"background-color: #EEEEEE; margin: 3px\">%s</span>' % terms[c]\n",
    "        \n",
    "    display(HTML(w))\n",
    "    \n",
    "    for m in clustered[i][0:15]:\n",
    "        printmd('* %s' % m[0].upper() + m[1:])\n",
    "    print ()\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe42c19-e0c3-44be-8581-144d41c49b45",
   "metadata": {},
   "source": [
    "Смотрим размерность векторов в данной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52e34d-928d-4b2e-9500-6a2b5ae6fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "message = 'Умение отлаживать пайплайны обработки данных в эирфлоу'\n",
    "print(vectorizer.fit_transform([message]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fed9e7-e85e-4b97-bba5-8d00fafec8f5",
   "metadata": {},
   "source": [
    "А теперь посмотрим размерность векторов при использовании spaСy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e5dbb-4cdc-4ddf-9259-768063c53ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "message = 'Умение отлаживать пайплайны обработки данных в эирфлоу'\n",
    "print(nlp(message).vector.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
